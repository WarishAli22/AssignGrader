{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea67ed80-f073-441a-8280-64dbab5a07be",
   "metadata": {},
   "source": [
    "### Create and run a local RAG pipeline from scratch\n",
    "\n",
    "The goal of this notebook is to build a RAG (Retrieval Augmented Generation) pipeline from scratch and have it run on a local machine.\n",
    "\n",
    "W we'd like to be able to open a PDF file, ask questio ) of it and have them answered by a Large Language Model (LLM).\r\n",
    "\r\n",
    "There are framewofor this workflow such asding LlamaIndex and LangChain, however, the goal of building from scratch is to be able to inspect and customize all the parts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fac13-1809-440d-9c2a-d64ec5efbb6a",
   "metadata": {},
   "source": [
    "### What is RAG and why do we use it\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "This just means \"when given a prompt, search relevant sources for the answer to that prompt and give an answer\"\n",
    "\"Here's a breakdown of each step:\n",
    "\n",
    "Retrieval - Get relevant resources given a query. For example, if the query is \"what are the macronutrients?\" the ideal results will contain information about protein, carbohydrates and fats (and possibly alcohol) rather than information about which tractors are the best for farming (though that is also cool information).\n",
    "\r\n",
    "Augmentation - LLMs are capable of generating text given a prompt. However, this generated text is designed to look right. And it often has some correct information, however, they are prone to hallucination (generating a result that looks like legit text but is factually wrong). In augmentation, we pass relevant information into the prompt and get an LLM to use that relevant information as the basis of its generation\n",
    "\n",
    ".\r\n",
    "Generation - This is where the LLM will generate a response that has been flavoured/augmented with the retrieved resources. In turn, this not only gives us a potentially more correct answer, it also gives us resources to investigate more (since we know which resources went into the prompt). prompt)..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b81b676-c951-4d23-9d0c-481dfaae7d67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get PDF document\n",
    "pdf_path = \"H:/mongol_empire.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859168ef-4d20-4779-a13a-09d0667b9e71",
   "metadata": {},
   "source": [
    "# What is a token \n",
    "A sub-word piece of text. For example, \"hello, world!\" could be split into [\"hello\", \",\", \"world\", \"!\"]. A token can be a whole word,\n",
    "part of a word or group of punctuation characters. 1 token ~= 4 characters in English, 100 tokens ~= 75 words.\n",
    "Text gets broken into tokens before being passed to an LLM. see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "\n",
    "### Token Count and why we care?\n",
    "When we pass these tokens to our LLMs and embeddings, there needs to be a size limit to how many tokens we pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "288a3393-16d3-4784-a427-912744bf6236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\user\\anaconda3_2\\lib\\site-packages (1.24.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from PyMuPDF) (1.24.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69f4bc1cd674a66aa4c58b296ae4ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'page_char_count': 1999,\n",
       "  'page_word_count': 344,\n",
       "  'page_sentence_count_raw': 13,\n",
       "  'page_token_count': 499.75,\n",
       "  'text': 'Mongol empire, empire founded by Genghis Khan in 1206. Originating from the Mongol heartland in the Steppe of central Asia, by the late 13th century it spanned from the Pacific Ocean in the east to the Danube River and the shores of the Persian Gulf in the west. At its peak, it covered some 9 million square miles (23 million square km) of territory, making it the largest contiguous land empire in world history The year 1206, when Temüjin, son of Yesügei, was elected Genghis Khan of a federation of tribes on the banks of the Onon River, must be regarded as the beginning of the Mongol empire. This federation not only consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but also other Turkic tribes. Before 1206 Genghis Khan was but one of the tribal leaders fighting for supremacy in the steppe regions south and southeast of Lake Baikal; his victories over the Kereit and then the Naiman Turks, however, gave him undisputed authority over the whole of what is now Mongolia. A series of campaigns, some of them carried out simultaneously, followed. The first attack (1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a northwestern border-state of China, and ended in a declaration of allegiance by the Xi Xia king. A subsequent campaign was aimed at north China, which at that time was ruled by the Tungusic Jin dynasty. The fall of Beijing in 1215 marked the loss of all the territory north of the Huang He (Yellow River) to the Mongols; during the following years the Jin empire was reduced to the role of a buffer state between the Mongols in the north and the Chinese Song empire in the south. Other campaigns were launched against central Asia. In 1218 the Khara-Khitai state in east Turkistan was absorbed into the empire. The assassination of Muslim subjects of Genghis Khan by the Khwārezmians in Otrar led to a war with the sultanate of Khwārezm (Khiva) in west Turkistan (1219–25). Bukhara, Samarkand, and the capital Urgench were taken and'},\n",
       " {'page_number': 1,\n",
       "  'page_char_count': 1664,\n",
       "  'page_word_count': 260,\n",
       "  'page_sentence_count_raw': 10,\n",
       "  'page_token_count': 416.0,\n",
       "  'text': 'sacked by Mongol armies (1220–21). Advance troops (after crossing the Caucasus) even penetrated into southern Russia and raided cities in Crimea (1223). The once prosperous region of Khwārezm suffered for centuries from the effects of the Mongol invasion which brought about not only the destruction of the prosperous towns but also the disintegration of the irrigation system on which agriculture in those parts depended. A similarly destructive campaign was launched against Xi Xia in 1226–27 because the Xi Xia king had refused to assist the Mongols in their expedition against Khwārezm. The death of Genghis Khan during that campaign (1227) increased the vindictiveness of the Mongols. The Xi Xia culture, a mixture of Chinese and Tibetan elements, with Buddhism as the state religion, was virtually annihilated. In 1227 the Mongol dominions stretched over the vast regions between the Caspian and China seas, bordering in the north on the sparsely populated forest belt of Siberia and in the south on the Pamirs, Tibet, and the central plains of China. This empire contained a multitude of different peoples, religions, and civilizations, and it is only natural to seek the motivating force behind this unparalleled expansion. Certainly the traditional antagonism between pastoral, nomadic steppe-dwellers and settled agricultural civilizations has to be taken into account. Raids by nomads from the steppe had always occurred from time to time wherever powerful nomadic tribes lived in the proximity of settled populations, but they had not usually taken on the dimensions of a bid for world hegemony or domination as in the case of Genghis Khan’s invasions.'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
    "!pip install PyMuPDF\n",
    "import fitz \n",
    "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm \n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and lists stats.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number\n",
    "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number,  # adjust page numbers since our PDF starts on page 42\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c26151-cd59-4727-93bd-1fc3798694eb",
   "metadata": {},
   "source": [
    "### Splitting Pages Into Sentences\n",
    "\n",
    "Easier to handle than larger pages of text, especially if pages are densely filled with text.\n",
    "There is no one best way of processing text before embedding and there are multiple ways to do it\n",
    "\n",
    "A simple method I've found helpful is to break the text into chunks. As in, chunk a page of text into groups of 10 or more sentences (this value is variable and can be changed to fit your needs).\n",
    "\n",
    "We can use an NLP library such as spaCy to do this \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016a4431-4658-4d3d-a58c-fc0a75718ff5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\anaconda3_2\\lib\\site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3_2\\lib\\site-packages (68.2.2)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-69.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: wheel in c:\\users\\user\\anaconda3_2\\lib\\site-packages (0.41.2)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.1 MB 495.5 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/2.1 MB 1.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.1 MB 1.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.5/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.1 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
      "   ---------------------------------------- 0.0/821.5 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 348.2/821.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 821.5/821.5 kB 13.1 MB/s eta 0:00:00\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\user\\anaconda3_2\\python.exe -m pip install -U pip setuptools wheel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.1/12.1 MB 1.7 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.3/12.1 MB 2.1 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/12.1 MB 2.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.7/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/12.1 MB 3.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.1 MB 6.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.1 MB 6.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.1 MB 6.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.1 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.2/12.1 MB 5.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.6/12.1 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.1 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.7/12.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.4/12.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/12.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.6/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.6/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.7/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.9/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.2/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.7/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.0/12.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.5/12.1 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.1 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.3/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.7/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 181.6/181.6 kB 10.7 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB ? eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 450.6/479.7 kB 13.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 479.7/479.7 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.6 MB 16.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.1/6.6 MB 13.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.6/6.6 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.2/6.6 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.7/6.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.2/6.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.2/6.6 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.4/6.6 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.7/6.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.9/6.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.1/6.6 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.4/6.6 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.8/6.6 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.6 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.4/6.6 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, langcodes, cloudpathlib, catalogue, blis, typer, srsly, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "-m pip install -U pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c422c00c-7389-45a7-887f-22027a30ecbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence.]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English \n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create a document instance as an example\n",
    "doc = nlp(\"This is a sentence. This another sentence.\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "# Access the sentences of the document\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c501a74-6d93-49d2-8fa6-056c0ba5544c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba07dcb2cda8491fb95b715685ed9a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    \n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcc06e4f-b08c-433d-bace-3225eb476e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1,\n",
       "  'page_char_count': 1664,\n",
       "  'page_word_count': 260,\n",
       "  'page_sentence_count_raw': 10,\n",
       "  'page_token_count': 416.0,\n",
       "  'text': 'sacked by Mongol armies (1220–21). Advance troops (after crossing the Caucasus) even penetrated into southern Russia and raided cities in Crimea (1223). The once prosperous region of Khwārezm suffered for centuries from the effects of the Mongol invasion which brought about not only the destruction of the prosperous towns but also the disintegration of the irrigation system on which agriculture in those parts depended. A similarly destructive campaign was launched against Xi Xia in 1226–27 because the Xi Xia king had refused to assist the Mongols in their expedition against Khwārezm. The death of Genghis Khan during that campaign (1227) increased the vindictiveness of the Mongols. The Xi Xia culture, a mixture of Chinese and Tibetan elements, with Buddhism as the state religion, was virtually annihilated. In 1227 the Mongol dominions stretched over the vast regions between the Caspian and China seas, bordering in the north on the sparsely populated forest belt of Siberia and in the south on the Pamirs, Tibet, and the central plains of China. This empire contained a multitude of different peoples, religions, and civilizations, and it is only natural to seek the motivating force behind this unparalleled expansion. Certainly the traditional antagonism between pastoral, nomadic steppe-dwellers and settled agricultural civilizations has to be taken into account. Raids by nomads from the steppe had always occurred from time to time wherever powerful nomadic tribes lived in the proximity of settled populations, but they had not usually taken on the dimensions of a bid for world hegemony or domination as in the case of Genghis Khan’s invasions.',\n",
       "  'sentences': ['sacked by Mongol armies (1220–21).',\n",
       "   'Advance troops (after crossing the Caucasus) even penetrated into southern Russia and raided cities in Crimea (1223).',\n",
       "   'The once prosperous region of Khwārezm suffered for centuries from the effects of the Mongol invasion which brought about not only the destruction of the prosperous towns but also the disintegration of the irrigation system on which agriculture in those parts depended.',\n",
       "   'A similarly destructive campaign was launched against Xi Xia in 1226–27 because the Xi Xia king had refused to assist the Mongols in their expedition against Khwārezm.',\n",
       "   'The death of Genghis Khan during that campaign (1227) increased the vindictiveness of the Mongols.',\n",
       "   'The Xi Xia culture, a mixture of Chinese and Tibetan elements, with Buddhism as the state religion, was virtually annihilated.',\n",
       "   'In 1227 the Mongol dominions stretched over the vast regions between the Caspian and China seas, bordering in the north on the sparsely populated forest belt of Siberia and in the south on the Pamirs, Tibet, and the central plains of China.',\n",
       "   'This empire contained a multitude of different peoples, religions, and civilizations, and it is only natural to seek the motivating force behind this unparalleled expansion.',\n",
       "   'Certainly the traditional antagonism between pastoral, nomadic steppe-dwellers and settled agricultural civilizations has to be taken into account.',\n",
       "   'Raids by nomads from the steppe had always occurred from time to time wherever powerful nomadic tribes lived in the proximity of settled populations, but they had not usually taken on the dimensions of a bid for world hegemony or domination as in the case of Genghis Khan’s invasions.'],\n",
       "  'page_sentence_count_spacy': 10}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1072e-e5e1-4a3e-b2a5-7980cf66b4ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Chunking Sentences\n",
    "\n",
    "Why do we do this?\r\n",
    "\r\n",
    "Easier to manage similar sized chunks of text.\r\n",
    "Don't overload the embedding models capacity for tokens (e.g. if an embedding model has a capacity of 384 tokens, there could be information loss if you try to embed a sequence of 400+ tokens).\r\n",
    "Our LLM context window (the amount of tokens an LLM can take in) may be limited and requires compute power so we want to make sure we're using it as well as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0b4e5c4-8e98-488c-a8a8-0814649ec6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c6e95d86d04ba58a5e2cd5f21ca4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0af10681-c127-4b4d-9156-86565ca65080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'page_char_count': 1999,\n",
       "  'page_word_count': 344,\n",
       "  'page_sentence_count_raw': 13,\n",
       "  'page_token_count': 499.75,\n",
       "  'text': 'Mongol empire, empire founded by Genghis Khan in 1206. Originating from the Mongol heartland in the Steppe of central Asia, by the late 13th century it spanned from the Pacific Ocean in the east to the Danube River and the shores of the Persian Gulf in the west. At its peak, it covered some 9 million square miles (23 million square km) of territory, making it the largest contiguous land empire in world history The year 1206, when Temüjin, son of Yesügei, was elected Genghis Khan of a federation of tribes on the banks of the Onon River, must be regarded as the beginning of the Mongol empire. This federation not only consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but also other Turkic tribes. Before 1206 Genghis Khan was but one of the tribal leaders fighting for supremacy in the steppe regions south and southeast of Lake Baikal; his victories over the Kereit and then the Naiman Turks, however, gave him undisputed authority over the whole of what is now Mongolia. A series of campaigns, some of them carried out simultaneously, followed. The first attack (1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a northwestern border-state of China, and ended in a declaration of allegiance by the Xi Xia king. A subsequent campaign was aimed at north China, which at that time was ruled by the Tungusic Jin dynasty. The fall of Beijing in 1215 marked the loss of all the territory north of the Huang He (Yellow River) to the Mongols; during the following years the Jin empire was reduced to the role of a buffer state between the Mongols in the north and the Chinese Song empire in the south. Other campaigns were launched against central Asia. In 1218 the Khara-Khitai state in east Turkistan was absorbed into the empire. The assassination of Muslim subjects of Genghis Khan by the Khwārezmians in Otrar led to a war with the sultanate of Khwārezm (Khiva) in west Turkistan (1219–25). Bukhara, Samarkand, and the capital Urgench were taken and',\n",
       "  'sentences': ['Mongol empire, empire founded by Genghis Khan in 1206.',\n",
       "   'Originating from the Mongol heartland in the Steppe of central Asia, by the late 13th century it spanned from the Pacific Ocean in the east to the Danube River and the shores of the Persian Gulf in the west.',\n",
       "   'At its peak, it covered some 9 million square miles (23 million square km) of territory, making it the largest contiguous land empire in world history The year 1206, when Temüjin, son of Yesügei, was elected Genghis Khan of a federation of tribes on the banks of the Onon River, must be regarded as the beginning of the Mongol empire.',\n",
       "   'This federation not only consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but also other Turkic tribes.',\n",
       "   'Before 1206 Genghis Khan was but one of the tribal leaders fighting for supremacy in the steppe regions south and southeast of Lake Baikal; his victories over the Kereit and then the Naiman Turks, however, gave him undisputed authority over the whole of what is now Mongolia.',\n",
       "   'A series of campaigns, some of them carried out simultaneously, followed.',\n",
       "   'The first attack (1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a northwestern border-state of China, and ended in a declaration of allegiance by the Xi Xia king.',\n",
       "   'A subsequent campaign was aimed at north China, which at that time was ruled by the Tungusic Jin dynasty.',\n",
       "   'The fall of Beijing in 1215 marked the loss of all the territory north of the Huang He (Yellow River) to the Mongols; during the following years the Jin empire was reduced to the role of a buffer state between the Mongols in the north and the Chinese Song empire in the south.',\n",
       "   'Other campaigns were launched against central Asia.',\n",
       "   'In 1218 the Khara-Khitai state in east Turkistan was absorbed into the empire.',\n",
       "   'The assassination of Muslim subjects of Genghis Khan by the Khwārezmians in Otrar led to a war with the sultanate of Khwārezm (Khiva) in west Turkistan (1219–25).',\n",
       "   'Bukhara, Samarkand, and the capital Urgench were taken and'],\n",
       "  'page_sentence_count_spacy': 13,\n",
       "  'sentence_chunks': [['Mongol empire, empire founded by Genghis Khan in 1206.',\n",
       "    'Originating from the Mongol heartland in the Steppe of central Asia, by the late 13th century it spanned from the Pacific Ocean in the east to the Danube River and the shores of the Persian Gulf in the west.',\n",
       "    'At its peak, it covered some 9 million square miles (23 million square km) of territory, making it the largest contiguous land empire in world history The year 1206, when Temüjin, son of Yesügei, was elected Genghis Khan of a federation of tribes on the banks of the Onon River, must be regarded as the beginning of the Mongol empire.',\n",
       "    'This federation not only consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but also other Turkic tribes.',\n",
       "    'Before 1206 Genghis Khan was but one of the tribal leaders fighting for supremacy in the steppe regions south and southeast of Lake Baikal; his victories over the Kereit and then the Naiman Turks, however, gave him undisputed authority over the whole of what is now Mongolia.',\n",
       "    'A series of campaigns, some of them carried out simultaneously, followed.',\n",
       "    'The first attack (1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a northwestern border-state of China, and ended in a declaration of allegiance by the Xi Xia king.',\n",
       "    'A subsequent campaign was aimed at north China, which at that time was ruled by the Tungusic Jin dynasty.',\n",
       "    'The fall of Beijing in 1215 marked the loss of all the territory north of the Huang He (Yellow River) to the Mongols; during the following years the Jin empire was reduced to the role of a buffer state between the Mongols in the north and the Chinese Song empire in the south.',\n",
       "    'Other campaigns were launched against central Asia.'],\n",
       "   ['In 1218 the Khara-Khitai state in east Turkistan was absorbed into the empire.',\n",
       "    'The assassination of Muslim subjects of Genghis Khan by the Khwārezmians in Otrar led to a war with the sultanate of Khwārezm (Khiva) in west Turkistan (1219–25).',\n",
       "    'Bukhara, Samarkand, and the capital Urgench were taken and']],\n",
       "  'num_chunks': 2}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e2200e0-ed5c-4f9c-b498-5a153754a873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb26065a8cdc419dbb7d68e4a98c3abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e41f8fdf-4c87-4ae5-884a-9ab02cfefc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1,\n",
       "  'sentence_chunk': 'sacked by Mongol armies (1220–21). Advance troops (after crossing the Caucasus) even penetrated into southern Russia and raided cities in Crimea (1223). The once prosperous region of Khwārezm suffered for centuries from the effects of the Mongol invasion which brought about not only the destruction of the prosperous towns but also the disintegration of the irrigation system on which agriculture in those parts depended. A similarly destructive campaign was launched against Xi Xia in 1226–27 because the Xi Xia king had refused to assist the Mongols in their expedition against Khwārezm. The death of Genghis Khan during that campaign (1227) increased the vindictiveness of the Mongols. The Xi Xia culture, a mixture of Chinese and Tibetan elements, with Buddhism as the state religion, was virtually annihilated. In 1227 the Mongol dominions stretched over the vast regions between the Caspian and China seas, bordering in the north on the sparsely populated forest belt of Siberia and in the south on the Pamirs, Tibet, and the central plains of China. This empire contained a multitude of different peoples, religions, and civilizations, and it is only natural to seek the motivating force behind this unparalleled expansion. Certainly the traditional antagonism between pastoral, nomadic steppe-dwellers and settled agricultural civilizations has to be taken into account. Raids by nomads from the steppe had always occurred from time to time wherever powerful nomadic tribes lived in the proximity of settled populations, but they had not usually taken on the dimensions of a bid for world hegemony or domination as in the case of Genghis Khan’s invasions.',\n",
       "  'chunk_char_count': 1664,\n",
       "  'chunk_word_count': 260,\n",
       "  'chunk_token_count': 416.0}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9e62c-7cb5-4fc7-b84b-a53b012a9dbd",
   "metadata": {},
   "source": [
    "## Embedding our text chunks\r\n",
    "While humans understand text, machines understand numbers best\n",
    "\n",
    "The most powerful thing about modern embeddings is that they are learned representations.\n",
    "\r\n",
    "Meaning rather than directly mapping words/tokens/characters to numbers directly (e.g. {\"a\": 0, \"b\": 1, \"c\": 3...}), the numerical representation of tokens is learned by going through large corpuses of text and figuring out how different tokens relate to each other.\r\n",
    "\r\n",
    "Ideally, embeddings of text will mean that similar meaning texts have similar numerical representati\n",
    "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order).\r\n",
    "\r\n",
    "Once our text samples are in embedding vectors, us humans will no longer be able to understand the.\r\n",
    "\r\n",
    "However, we don't needto.\r\n",
    "\r\n",
    "The embedding vectors are for our computers to undertand.\r\n",
    "\r\n",
    "We'll use our computers to find patterns in the embeddings and then we can use their text mappings to further our unders\n",
    "\n",
    "To do so, we'll use the sentence-transformers library which contains many pre-trained embedding models.\n",
    "\r\n",
    "Specifically, we'll get the all-mpnet-base-v2 model (you can see the model's intended use on the Hugging Face model card).tanding.on.\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a695ed39-bf2c-4ef8-afcd-cbcaf7b95c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (4.39.0.dev0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3_2\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
      "   ---------------------------------------- 0.0/163.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/163.3 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 30.7/163.3 kB 640.0 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 81.9/163.3 kB 762.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 153.6/163.3 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- 163.3/163.3 kB 975.0 kB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a9d018b2-a2d1-477d-8bf2-1fd7929ccbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
      "Embedding: [-2.07982566e-02  3.03164721e-02 -2.01217886e-02  6.86484799e-02\n",
      " -2.55256146e-02 -8.47687945e-03 -2.07216086e-04 -6.32377639e-02\n",
      "  2.81606950e-02 -3.33353765e-02  3.02634221e-02  5.30721694e-02\n",
      " -5.03526740e-02  2.62288526e-02  3.33313718e-02 -4.51577567e-02\n",
      "  3.63045111e-02 -1.37120660e-03 -1.20171243e-02  1.14947073e-02\n",
      "  5.04510999e-02  4.70856875e-02  2.11913846e-02  5.14606386e-02\n",
      " -2.03746744e-02 -3.58889401e-02 -6.67769345e-04 -2.94393916e-02\n",
      "  4.95859198e-02 -1.05639435e-02 -1.52014121e-02 -1.31760724e-03\n",
      "  4.48197052e-02  1.56023102e-02  8.60379259e-07 -1.21393567e-03\n",
      " -2.37978958e-02 -9.09396622e-04  7.34487548e-03 -2.53931922e-03\n",
      "  5.23370430e-02 -4.68043461e-02  1.66214649e-02  4.71579656e-02\n",
      " -4.15599123e-02  9.01964959e-04  3.60278338e-02  3.42214145e-02\n",
      "  9.68227461e-02  5.94829284e-02 -1.64984427e-02 -3.51249203e-02\n",
      "  5.92515618e-03 -7.07914936e-04 -2.41031069e-02  3.49740647e-02\n",
      " -2.94746831e-02  6.04267605e-03 -9.80649609e-03  2.83217877e-02\n",
      " -1.85375996e-02  3.63213345e-02  1.30292084e-02 -3.71232852e-02\n",
      "  5.27256653e-02 -1.19707072e-02 -7.18082562e-02  1.24431830e-02\n",
      " -6.70565898e-03  7.42154419e-02  1.16356099e-02 -1.74533520e-02\n",
      " -1.82405561e-02 -1.88931040e-02  2.82414965e-02  1.32829621e-02\n",
      " -3.51910070e-02  8.87303497e-04  5.79572581e-02  3.22093666e-02\n",
      " -3.48581700e-03  4.13768925e-02  1.44358212e-02 -3.28044333e-02\n",
      " -9.79089830e-03 -3.16492803e-02  4.23870832e-02 -4.70846593e-02\n",
      " -2.08936948e-02 -1.91249475e-02 -1.22627318e-02  1.01606119e-02\n",
      "  3.91921811e-02 -2.61896029e-02  1.09028025e-02  1.35723455e-02\n",
      " -5.79267442e-02 -3.21500339e-02 -5.75722242e-03 -2.43515819e-02\n",
      "  5.23416586e-02  5.46122622e-03 -2.30995864e-02  2.57174182e-03\n",
      " -6.63347095e-02  3.54125388e-02 -1.03907185e-02  2.25410350e-02\n",
      " -1.84573755e-02 -2.42007170e-02 -4.78365645e-02 -4.79226280e-03\n",
      " -5.34138456e-02  3.01790368e-02 -1.56130800e-02 -5.51477075e-02\n",
      " -3.91874164e-02  5.92153035e-02 -3.47646885e-02  9.68121458e-03\n",
      "  2.13415660e-02  2.30416879e-02  1.91713125e-02  2.77378727e-02\n",
      " -7.73506099e-03  1.04445675e-02 -2.67719738e-02 -2.40199901e-02\n",
      " -1.92290153e-02  3.91502166e-03 -2.54714601e-02  3.61943021e-02\n",
      "  5.12867346e-02 -8.41692369e-03 -3.13830040e-02  1.47483572e-02\n",
      "  2.13940330e-02 -3.84900570e-02  2.01945361e-02  1.20766070e-02\n",
      " -3.12069687e-03  7.84036517e-03  3.30335833e-03 -4.94357497e-02\n",
      "  5.83886579e-02  3.26138106e-03  4.84486297e-03 -4.50682603e-02\n",
      "  2.45683100e-02  3.55428196e-02 -5.32506481e-02  9.21152830e-02\n",
      "  2.04394683e-02 -3.36951762e-02 -6.19803444e-02 -2.11039223e-02\n",
      "  7.82358944e-02  5.11908084e-02  5.93170822e-02 -1.25129256e-04\n",
      "  4.96350415e-02 -1.55722722e-02 -3.35677830e-03  1.82016473e-02\n",
      " -2.73444057e-02 -1.08772190e-02  1.41476188e-02  1.09877670e-02\n",
      "  4.32553655e-03  8.23311210e-02 -9.85348946e-04  7.58791342e-02\n",
      "  9.44995973e-03  2.37688012e-02  1.61927920e-02  6.24993779e-02\n",
      "  4.75922339e-02 -3.92628647e-03  9.07524377e-02  4.49874364e-02\n",
      " -3.47131528e-02  2.14077160e-02 -3.35604139e-02  4.93849181e-02\n",
      "  1.08669708e-02  2.63447817e-02 -3.26089300e-02  8.00303370e-02\n",
      "  9.29766521e-03  7.16578634e-03 -2.79172212e-02 -3.06821149e-02\n",
      "  4.01061913e-03 -4.93906885e-02 -3.13769816e-03  4.00537923e-02\n",
      " -3.97855155e-02  5.48013933e-02  1.36412864e-05 -8.38373303e-02\n",
      " -1.21547673e-02  3.40949893e-02  3.22405179e-03  6.11846372e-02\n",
      "  5.60066998e-02  9.62872524e-03  2.54616365e-02 -4.64168601e-02\n",
      " -3.98901291e-02  7.68132433e-02  2.28409059e-02 -2.26568729e-02\n",
      " -1.91193763e-02 -6.53029233e-02  4.56781238e-02 -4.43655578e-03\n",
      "  1.49631789e-02 -2.15078071e-02  2.74248281e-03  1.90358367e-02\n",
      "  5.91888689e-02 -2.47569028e-02  3.66144180e-02  5.63083962e-02\n",
      " -8.86448007e-03 -1.74324550e-02 -1.03287946e-03  2.47666650e-02\n",
      "  1.30763082e-02  5.04632704e-02 -5.28495060e-03  5.92397861e-02\n",
      "  6.29906207e-02 -4.36783098e-02 -4.97830138e-02  5.56296743e-02\n",
      " -2.44853757e-02 -8.26754868e-02  2.04910524e-02 -1.06446281e-01\n",
      "  6.64845388e-03  2.97304280e-02 -2.36440096e-02 -8.84617586e-03\n",
      "  2.45557050e-03 -3.35234441e-02  7.52212554e-02 -5.89879937e-02\n",
      " -3.67808118e-02  3.41542736e-02  5.41130789e-02 -1.74904820e-02\n",
      "  1.33920657e-02  4.71682884e-02  1.46116298e-02 -2.12310813e-02\n",
      " -6.55338541e-02  1.23857735e-02  2.76074503e-02 -8.02162662e-03\n",
      " -4.59636562e-02 -8.22442025e-03  9.16955061e-03 -1.56399198e-02\n",
      "  7.54623068e-03  1.58310484e-03 -3.03958375e-02 -5.10671027e-02\n",
      "  1.96313597e-02  1.26263378e-02 -1.51738070e-03  2.02891324e-02\n",
      "  1.37817273e-02  1.49110425e-02  2.50766929e-02 -3.62870470e-02\n",
      "  1.08085526e-02  2.74132728e-03  1.81510709e-02  5.39872423e-02\n",
      " -4.74542268e-02 -4.28731255e-02 -2.89914440e-02  2.13235430e-02\n",
      " -3.85161191e-02  6.31922409e-02 -5.77975810e-02  3.77886067e-03\n",
      " -2.54394282e-02 -1.77206253e-04  9.08244308e-03  1.59095023e-02\n",
      "  4.11799885e-02 -3.94367725e-02 -9.64433793e-03  1.30791487e-02\n",
      "  6.87962696e-02  4.32192571e-02  7.54012319e-04  6.77741542e-02\n",
      "  4.93705682e-02 -3.47821205e-03 -1.06055206e-02  6.72491128e-03\n",
      " -1.39062125e-02  4.88276593e-02 -1.05735259e-02  3.50227207e-03\n",
      "  2.90227635e-03  2.40043942e-02  1.20271863e-02 -2.09797379e-02\n",
      " -2.39111856e-02  3.26579511e-02 -1.01325335e-03 -5.92757529e-03\n",
      " -7.40534300e-03  3.63147468e-03 -2.26698760e-02 -2.21241694e-02\n",
      "  3.86996605e-02  1.72321722e-02  3.85919660e-02 -5.04711606e-02\n",
      " -3.42145003e-02 -4.00444008e-02 -3.57910767e-02 -4.62561101e-02\n",
      "  6.70232177e-02 -4.61648731e-03 -3.29676457e-03  2.08444316e-02\n",
      " -5.14257140e-03 -5.00850156e-02  2.22503953e-02  4.66933660e-02\n",
      "  1.36208730e-02  1.77529939e-02  4.28078696e-03 -2.79332101e-02\n",
      " -1.93420667e-02 -3.87859792e-02 -3.09554953e-02 -6.64134100e-02\n",
      " -1.13434205e-02  1.64267253e-02  1.77629367e-02 -2.28222692e-03\n",
      " -3.30087133e-02 -1.36262819e-03 -2.17933990e-02 -2.67508328e-02\n",
      " -1.26375826e-02  1.61869195e-03 -4.95672636e-02  7.85446092e-02\n",
      "  4.10962999e-02  9.65916924e-03 -1.14643238e-02  1.68855255e-03\n",
      "  5.37663028e-02  2.05533439e-03 -4.11199816e-02  1.46330129e-02\n",
      " -3.75564247e-02 -3.35690193e-02  5.19255456e-03 -6.33089095e-02\n",
      "  3.32963467e-02  8.76118802e-03  1.33858249e-03 -3.95745598e-03\n",
      " -1.61677785e-02  8.26746970e-02  4.75944988e-02 -3.43055241e-02\n",
      "  2.50881258e-02 -3.50977145e-02  3.68657336e-02  4.12647892e-03\n",
      "  4.16018292e-02 -1.35181695e-01 -4.76338156e-02 -1.20025780e-02\n",
      " -3.48891653e-02  3.25455107e-02 -2.93574808e-03 -4.85054683e-03\n",
      " -1.04223721e-01  2.78610196e-02  1.41570335e-02  3.94395739e-02\n",
      " -3.88806835e-02 -1.42463353e-02 -5.19984066e-02  8.92734993e-03\n",
      " -1.99770723e-02 -2.51724906e-02 -3.41299921e-02  1.93041507e-02\n",
      " -5.20208105e-02 -6.72000423e-02 -9.46364272e-03 -1.25588337e-03\n",
      " -5.66048697e-02  2.62098834e-02  9.91584640e-03  4.38286401e-02\n",
      "  2.26643635e-03 -3.11895534e-02 -6.25467151e-02 -3.87793221e-02\n",
      " -6.83939159e-02  4.93721813e-02  5.85507713e-02 -4.08729576e-02\n",
      " -1.98638272e-02 -2.12634131e-02  4.98037338e-02 -4.51748855e-02\n",
      " -2.37141736e-02  2.32675131e-02  1.00594789e-01  9.87117738e-03\n",
      " -1.38014946e-02 -5.21041490e-02  9.08211898e-03  1.72427502e-02\n",
      "  5.91431707e-02  2.62336619e-02 -7.04641733e-03 -1.50032202e-02\n",
      " -3.76660726e-03  6.28256099e-03 -5.23981564e-02 -4.96638641e-02\n",
      "  3.06610987e-02 -3.33649153e-03  2.34911256e-02 -8.58830214e-02\n",
      " -4.62449603e-02  5.59701063e-02  3.09077790e-04  2.01729126e-02\n",
      " -2.98053585e-03  1.76646207e-02  1.54669825e-02 -7.41717964e-02\n",
      "  7.34991580e-03 -1.05015710e-02  2.45247334e-02  1.36879142e-02\n",
      " -1.17804101e-02  4.51544821e-02  3.29039432e-02 -3.50391283e-03\n",
      " -2.71314774e-02 -5.27363792e-02 -4.60164174e-02  2.22848598e-02\n",
      "  2.62271818e-02  5.56152314e-03  1.45789087e-02 -2.97145732e-02\n",
      "  3.57043035e-02  2.22534109e-02  3.89617123e-02 -7.92634860e-02\n",
      " -9.01092123e-03  2.19013020e-02 -5.49055077e-03  8.69955961e-03\n",
      "  4.33031097e-02 -2.12631393e-02  1.13291936e-02 -6.33698776e-02\n",
      "  3.63723785e-02  2.67442483e-02 -6.64252117e-02  1.70499217e-02\n",
      " -2.79691033e-02  2.36352650e-03 -1.81953069e-02  1.52955540e-02\n",
      " -8.50432832e-03  1.16647528e-02 -9.75921899e-02 -2.92093307e-02\n",
      " -5.42547554e-02  3.61234769e-02  3.25117037e-02  8.26976448e-03\n",
      " -2.96509039e-04  1.11555485e-02 -3.85188162e-02  2.36161184e-02\n",
      "  9.85924620e-03  5.73998354e-02  4.86061014e-02 -1.37579124e-02\n",
      " -6.19220687e-03  1.11973044e-02 -3.37175280e-02 -1.10515440e-02\n",
      " -7.08333775e-02 -1.01816421e-02 -3.66010889e-02 -1.55560682e-02\n",
      " -2.13110503e-02 -1.02760987e-02 -4.35733981e-02  5.55186607e-02\n",
      " -3.76548432e-02  5.29252402e-02 -3.45223956e-02 -2.43003643e-03\n",
      "  7.25553334e-02  4.45071794e-03  4.71417829e-02 -9.43883136e-03\n",
      " -1.98978763e-02  5.71899898e-02  8.60541090e-02 -5.25057875e-02\n",
      " -1.39549579e-02  1.17373187e-02  1.33974142e-02 -4.73052822e-02\n",
      " -5.41674271e-02  4.62725647e-02 -2.58970130e-02  1.51415206e-02\n",
      "  3.38945091e-02 -3.78259388e-03 -5.76043352e-02 -1.60082132e-02\n",
      "  2.42738798e-02  3.37360799e-02 -1.96821149e-02 -2.53464207e-02\n",
      " -4.75617088e-02 -5.68755195e-02 -2.28193980e-02  3.83187644e-02\n",
      " -1.78330932e-02  1.35964258e-02  7.85971119e-04  9.74010397e-03\n",
      "  3.34298573e-02 -2.60133799e-02 -7.38567254e-03  3.56451347e-02\n",
      " -2.68532522e-02 -7.53624737e-02 -2.66983844e-02 -4.46457420e-33\n",
      " -3.31646577e-02  1.41703533e-02 -3.92909423e-02 -3.46318744e-02\n",
      " -5.88671537e-03 -1.18212104e-02  1.53951347e-02  1.18473507e-02\n",
      "  1.07757309e-02  3.62140313e-02  7.87953101e-03 -2.31845602e-02\n",
      "  1.07623274e-02  1.72346458e-02  9.54222807e-04  2.83640325e-02\n",
      "  2.37419251e-02 -1.48058021e-02  1.24199816e-03  3.52352834e-03\n",
      "  2.33735647e-02  5.58307879e-02  5.38327657e-02 -3.74079086e-02\n",
      " -2.11805627e-02  1.52721987e-04 -7.27788452e-03  5.50555997e-03\n",
      "  3.05823591e-02  4.54633385e-02 -3.35786864e-02  3.16142589e-02\n",
      " -2.56394478e-03  3.96355316e-02 -1.47573762e-02  5.67167737e-02\n",
      " -5.62787689e-02 -5.04600070e-03  3.56154926e-02 -2.76198778e-02\n",
      " -2.32292246e-02 -4.63292263e-02 -3.70919742e-02 -4.23189141e-02\n",
      "  3.70306894e-02  7.88717251e-03  3.85176092e-02  1.74771517e-03\n",
      "  5.62761724e-03  6.18108222e-03 -6.90268800e-02 -9.42962524e-03\n",
      " -7.74673419e-03  1.68350022e-02  1.22767640e-02  2.26406269e-02\n",
      "  1.21008847e-02  1.11743463e-02  1.21539105e-02 -1.16862003e-02\n",
      " -4.41612750e-02  2.30047256e-02  2.20672470e-02 -5.87504469e-02\n",
      " -3.96428294e-02  6.83135614e-02 -3.29948142e-02 -3.66774835e-02\n",
      " -3.53654809e-02  1.76185220e-02  6.95639662e-03  5.92692941e-02\n",
      "  4.12156396e-02  7.98109397e-02 -5.36561338e-03  1.14238542e-02\n",
      " -2.96388436e-02 -1.15411934e-02  2.22812667e-02  7.93182850e-03\n",
      "  2.60356124e-02  1.28212059e-02  1.71345863e-02 -6.90187095e-03\n",
      " -1.07603259e-02  1.35714412e-02 -9.90783563e-04 -6.16075508e-02\n",
      "  4.40514088e-02 -8.26596690e-04 -2.78341137e-02 -1.23619307e-02\n",
      "  1.34629635e-02 -3.85745391e-02  1.08701899e-03  2.18712352e-02\n",
      " -3.32398564e-02  1.84615962e-02 -5.10115642e-03  3.74664888e-02\n",
      " -3.67541076e-03 -2.19246596e-02 -4.96479636e-03 -9.59840417e-03\n",
      "  2.33591199e-02  1.04877055e-02  4.38722000e-02 -1.51424343e-02\n",
      " -6.30309433e-02  8.23258981e-03 -1.09130666e-02 -4.06409539e-02\n",
      " -6.21691085e-02  2.21326239e-02 -2.71434374e-02  4.05539386e-02\n",
      " -8.09448957e-03 -1.76413218e-03  3.01526580e-02 -5.42265596e-03\n",
      " -4.69821766e-02 -1.73768848e-02  4.11630683e-02  3.20634656e-02\n",
      " -2.22944077e-02 -1.58161968e-02 -4.50720638e-02  5.69486395e-02\n",
      "  4.71595861e-02 -5.78058660e-02  1.32475290e-02 -4.71290434e-03\n",
      "  1.66824464e-07  4.81090620e-02  5.03628254e-02  5.45263514e-02\n",
      "  2.07568631e-02 -1.19080525e-02 -6.37493236e-03  5.26365591e-03\n",
      "  7.21949264e-02 -2.21762750e-02  2.20103152e-02 -9.90482513e-04\n",
      " -1.37163652e-02  6.89204829e-03  2.46912576e-02 -1.39462024e-01\n",
      "  2.56980839e-03 -4.64826524e-02 -4.04967479e-02 -6.08555451e-02\n",
      " -1.53213013e-02  1.36129931e-01  9.45034772e-02  4.25741337e-02\n",
      "  4.67131250e-02 -2.30678059e-02 -1.20966183e-02  3.86672989e-02\n",
      "  2.11647432e-03 -2.51473375e-02 -1.15075940e-02 -3.46506275e-02\n",
      " -2.29533873e-02 -6.33848971e-03 -3.05175781e-02 -1.56236580e-02\n",
      "  1.39513947e-02  3.27492919e-04  2.00324017e-03  4.15103929e-03\n",
      " -2.22924799e-02 -3.62589881e-02 -2.36579627e-02 -1.87817365e-02\n",
      " -1.96288954e-02  4.52126004e-02 -8.12568590e-02 -2.14568749e-02\n",
      " -4.41543311e-02 -2.68475953e-02  2.01974381e-02  2.82992143e-03\n",
      " -1.95011664e-02 -3.45331132e-02  2.26913821e-02  3.78326066e-02\n",
      " -1.02543924e-02 -2.19759904e-03 -8.96744579e-02 -4.50031087e-02\n",
      "  8.09701905e-03 -2.05805562e-02 -2.02998742e-02 -2.09922381e-02\n",
      " -1.79404858e-02  5.81897683e-02 -7.63652567e-03  1.50847323e-02\n",
      "  1.78279744e-34  4.86179367e-02  4.22228388e-02  4.71595675e-02\n",
      "  5.89047298e-02  3.99785303e-02 -5.27071692e-02  1.56905465e-02\n",
      " -5.25075651e-04  1.13651864e-02 -6.56410456e-02 -2.20849402e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cpu\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n",
    "\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3338d5c-1410-42b9-be75-37ccfe476530",
   "metadata": {},
   "source": [
    "### Note: No matter the size of the text input to our all-mpnet-base-v2 model, it will be turned into an embedding size of (768,). This value is fixed. So whether a sentence is 1 token long or 1000 tokens long, it will be truncated/padded with zeros to size 384 and then turned into an embedding vector of size (768,). Of course, other embedding models may have different input/output shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e9ce062-370d-458e-ba3f-92f4950c25ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6e2a0612eb4be182c55507dbdc9217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment to see how long it takes to create embeddings on CPU\n",
    "# Make sure the model is on the CPU\n",
    "embedding_model.to(\"cpu\")\n",
    "\n",
    "# Embed each chunk one by one\n",
    "for item in tqdm(pages_and_chunks):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9769cbd8-9c77-4ece-82dd-e20f2f172e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mongol empire, empire founded by Genghis Khan in 1206. Originating from the Mongol heartland in the Steppe of central Asia, by the late 13th century it spanned from the Pacific Ocean in the east to the Danube River and the shores of the Persian Gulf in the west. At its peak, it covered some 9 million square miles (23 million square km) of territory, making it the largest contiguous land empire in world history The year 1206, when Temüjin, son of Yesügei, was elected Genghis Khan of a federation of tribes on the banks of the Onon River, must be regarded as the beginning of the Mongol empire. This federation not only consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but also other Turkic tribes. Before 1206 Genghis Khan was but one of the tribal leaders fighting for supremacy in the steppe regions south and southeast of Lake Baikal; his victories over the Kereit and then the Naiman Turks, however, gave him undisputed authority over the whole of what is now Mongolia. A series of campaigns, some of them carried out simultaneously, followed. The first attack (1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a northwestern border-state of China, and ended in a declaration of allegiance by the Xi Xia king. A subsequent campaign was aimed at north China, which at that time was ruled by the Tungusic Jin dynasty. The fall of Beijing in 1215 marked the loss of all the territory north of the Huang He (Yellow River) to the Mongols; during the following years the Jin empire was reduced to the role of a buffer state between the Mongols in the north and the Chinese Song empire in the south. Other campaigns were launched against central Asia.',\n",
       " 'In 1218 the Khara-Khitai state in east Turkistan was absorbed into the empire. The assassination of Muslim subjects of Genghis Khan by the Khwārezmians in Otrar led to a war with the sultanate of Khwārezm (Khiva) in west Turkistan (1219–25). Bukhara, Samarkand, and the capital Urgench were taken and',\n",
       " 'sacked by Mongol armies (1220–21). Advance troops (after crossing the Caucasus) even penetrated into southern Russia and raided cities in Crimea (1223). The once prosperous region of Khwārezm suffered for centuries from the effects of the Mongol invasion which brought about not only the destruction of the prosperous towns but also the disintegration of the irrigation system on which agriculture in those parts depended. A similarly destructive campaign was launched against Xi Xia in 1226–27 because the Xi Xia king had refused to assist the Mongols in their expedition against Khwārezm. The death of Genghis Khan during that campaign (1227) increased the vindictiveness of the Mongols. The Xi Xia culture, a mixture of Chinese and Tibetan elements, with Buddhism as the state religion, was virtually annihilated. In 1227 the Mongol dominions stretched over the vast regions between the Caspian and China seas, bordering in the north on the sparsely populated forest belt of Siberia and in the south on the Pamirs, Tibet, and the central plains of China. This empire contained a multitude of different peoples, religions, and civilizations, and it is only natural to seek the motivating force behind this unparalleled expansion. Certainly the traditional antagonism between pastoral, nomadic steppe-dwellers and settled agricultural civilizations has to be taken into account. Raids by nomads from the steppe had always occurred from time to time wherever powerful nomadic tribes lived in the proximity of settled populations, but they had not usually taken on the dimensions of a bid for world hegemony or domination as in the case of Genghis Khan’s invasions.']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn text chunks into a single list\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks]\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e3c28a1-3a8e-46c3-aeaf-201c964ed139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.86 s\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0156, -0.0241, -0.0123,  ...,  0.0545, -0.0024, -0.0283],\n",
       "        [ 0.0277, -0.0080,  0.0032,  ...,  0.0597, -0.0321,  0.0079],\n",
       "        [ 0.0235, -0.0350,  0.0030,  ...,  0.0582, -0.0390, -0.0166]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Embed all texts in batches\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb06f3-236c-42e3-b104-f1525ae8a10f",
   "metadata": {},
   "source": [
    "### Saving embeddings to csv for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c64a481-361f-4141-9ae8-d2291a7ad4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mongol empire, empire founded by Genghis Khan ...</td>\n",
       "      <td>1698</td>\n",
       "      <td>295</td>\n",
       "      <td>424.5</td>\n",
       "      <td>[-0.0156282205, -0.0241277367, -0.0123113962, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In 1218 the Khara-Khitai state in east Turkist...</td>\n",
       "      <td>300</td>\n",
       "      <td>49</td>\n",
       "      <td>75.0</td>\n",
       "      <td>[0.0276959464, -0.00797973946, 0.00317786518, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sacked by Mongol armies (1220–21). Advance tro...</td>\n",
       "      <td>1664</td>\n",
       "      <td>260</td>\n",
       "      <td>416.0</td>\n",
       "      <td>[0.0234714299, -0.0350027271, 0.00303653511, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            0  Mongol empire, empire founded by Genghis Khan ...   \n",
       "1            0  In 1218 the Khara-Khitai state in east Turkist...   \n",
       "2            1  sacked by Mongol armies (1220–21). Advance tro...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0              1698               295              424.5   \n",
       "1               300                49               75.0   \n",
       "2              1664               260              416.0   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.0156282205, -0.0241277367, -0.0123113962, ...  \n",
       "1  [0.0276959464, -0.00797973946, 0.00317786518, ...  \n",
       "2  [0.0234714299, -0.0350027271, 0.00303653511, -...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save embeddings to file\n",
    "import pandas as pd\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d91de6-0221-49cb-9f72-745b063d84df",
   "metadata": {},
   "source": [
    "### Turning embeddings to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abf9fa67-cd46-447a-beec-40c0be5f38ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "65bde923-8342-46f0-a074-3c6591f09d75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "\"\"\"Readying Our Embedding Model\"\"\"\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=device) # choose the device to load the model to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bba799-8bb8-4bf7-a2c2-b33e3b3dac72",
   "metadata": {},
   "source": [
    "## Similarity measures: dot product\n",
    "- Measure of magnitude and direction between two vectors\r\n",
    "- Vectors that are aligned in direction and magnitude have a higher positive value\r\n",
    "- Vectors that are opposite in direction and magnitude have a higher negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e1dc78c-0804-4f28-9c19-6fa634fa34cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Attack\n",
      "Time take to get scores on 1 embeddings: 0.00090 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.0568]),\n",
       "indices=tensor([0]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define the query\n",
    "query = \"Attack\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query to the same numerical space as the text examples \n",
    "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# 3. Get similarity scores with the dot product (wLet's time this to see)\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# 4. Get the top-k results (we'll keep this to 5)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=1)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8de1e12-0f8c-4cf6-9bda-7f7ddeab6be4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9137f9a-7602-429f-8095-0a1498502ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'Attack'\n",
      "\n",
      "Results:\n",
      "Score: 0.0568\n",
      "Text:\n",
      "Mongol empire, empire founded by Genghis Khan in 1206. Originating from the\n",
      "Mongol heartland in the Steppe of central Asia, by the late 13th century it\n",
      "spanned from the Pacific Ocean in the east to the Danube River and the shores of\n",
      "the Persian Gulf in the west. At its peak, it covered some 9 million square\n",
      "miles (23 million square km) of territory, making it the largest contiguous land\n",
      "empire in world history The year 1206, when Temüjin, son of Yesügei, was elected\n",
      "Genghis Khan of a federation of tribes on the banks of the Onon River, must be\n",
      "regarded as the beginning of the Mongol empire. This federation not only\n",
      "consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but\n",
      "also other Turkic tribes. Before 1206 Genghis Khan was but one of the tribal\n",
      "leaders fighting for supremacy in the steppe regions south and southeast of Lake\n",
      "Baikal; his victories over the Kereit and then the Naiman Turks, however, gave\n",
      "him undisputed authority over the whole of what is now Mongolia. A series of\n",
      "campaigns, some of them carried out simultaneously, followed. The first attack\n",
      "(1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a\n",
      "northwestern border-state of China, and ended in a declaration of allegiance by\n",
      "the Xi Xia king. A subsequent campaign was aimed at north China, which at that\n",
      "time was ruled by the Tungusic Jin dynasty. The fall of Beijing in 1215 marked\n",
      "the loss of all the territory north of the Huang He (Yellow River) to the\n",
      "Mongols; during the following years the Jin empire was reduced to the role of a\n",
      "buffer state between the Mongols in the north and the Chinese Song empire in the\n",
      "south. Other campaigns were launched against central Asia.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3422934-f6a9-4213-8d54-1133b9c3b823",
   "metadata": {},
   "source": [
    "### Running Our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2b3e28b-c232-4b30-b639-14b918aa5be0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' long and has a rhyme scheme of ABABCDCD.\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    \"K:/llama2_GGUF_cacheDir/models--TheBloke--Llama-2-7B-Chat-GGUF/TheBloke/Mistral-7B-OpenOrca-GGUF\",\n",
    "    model_file=\"mistral-7b-openorca.Q5_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers = 12                                                               \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3086e4eb-c1a2-4b33-a082-5db4a57c66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=1,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=1):\n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e8746754-1c6b-424f-b7d3-fa54366a7bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 1 embeddings: 0.00012 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0059]]), tensor([[0]]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Loss of territory\"\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5694e68-4921-485a-a9a5-fe6e369042ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 3 embeddings: 0.00006 seconds.\n",
      "Query: Loss of territory\n",
      "\n",
      "Results:\n",
      "Score: 0.2860\n",
      "In 1218 the Khara-Khitai state in east Turkistan was absorbed into the empire.\n",
      "The assassination of Muslim subjects of Genghis Khan by the Khwārezmians in\n",
      "Otrar led to a war with the sultanate of Khwārezm (Khiva) in west Turkistan\n",
      "(1219–25). Bukhara, Samarkand, and the capital Urgench were taken and\n",
      "Page number: 0\n",
      "\n",
      "\n",
      "Score: 0.2619\n",
      "sacked by Mongol armies (1220–21). Advance troops (after crossing the Caucasus)\n",
      "even penetrated into southern Russia and raided cities in Crimea (1223). The\n",
      "once prosperous region of Khwārezm suffered for centuries from the effects of\n",
      "the Mongol invasion which brought about not only the destruction of the\n",
      "prosperous towns but also the disintegration of the irrigation system on which\n",
      "agriculture in those parts depended. A similarly destructive campaign was\n",
      "launched against Xi Xia in 1226–27 because the Xi Xia king had refused to assist\n",
      "the Mongols in their expedition against Khwārezm. The death of Genghis Khan\n",
      "during that campaign (1227) increased the vindictiveness of the Mongols. The Xi\n",
      "Xia culture, a mixture of Chinese and Tibetan elements, with Buddhism as the\n",
      "state religion, was virtually annihilated. In 1227 the Mongol dominions\n",
      "stretched over the vast regions between the Caspian and China seas, bordering in\n",
      "the north on the sparsely populated forest belt of Siberia and in the south on\n",
      "the Pamirs, Tibet, and the central plains of China. This empire contained a\n",
      "multitude of different peoples, religions, and civilizations, and it is only\n",
      "natural to seek the motivating force behind this unparalleled expansion.\n",
      "Certainly the traditional antagonism between pastoral, nomadic steppe-dwellers\n",
      "and settled agricultural civilizations has to be taken into account. Raids by\n",
      "nomads from the steppe had always occurred from time to time wherever powerful\n",
      "nomadic tribes lived in the proximity of settled populations, but they had not\n",
      "usually taken on the dimensions of a bid for world hegemony or domination as in\n",
      "the case of Genghis Khan’s invasions.\n",
      "Page number: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the texts of the top scores\n",
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e7dc35b-acf6-4e43-ad4f-67b119ad45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8caec42c-dcd8-4e3b-b666-6cf10cdba05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Mongol empire, empire founded by Genghis Khan in 1206. Originating from the Mongol heartland in the Steppe of central Asia, by the late 13th century it spanned from the Pacific Ocean in the east to the Danube River and the shores of the Persian Gulf in the west. At its peak, it covered some 9 million square miles (23 million square km) of territory, making it the largest contiguous land empire in world history The year 1206, when Temüjin, son of Yesügei, was elected Genghis Khan of a federation of tribes on the banks of the Onon River, must be regarded as the beginning of the Mongol empire. This federation not only consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but also other Turkic tribes. Before 1206 Genghis Khan was but one of the tribal leaders fighting for supremacy in the steppe regions south and southeast of Lake Baikal; his victories over the Kereit and then the Naiman Turks, however, gave him undisputed authority over the whole of what is now Mongolia. A series of campaigns, some of them carried out simultaneously, followed. The first attack (1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a northwestern border-state of China, and ended in a declaration of allegiance by the Xi Xia king. A subsequent campaign was aimed at north China, which at that time was ruled by the Tungusic Jin dynasty. The fall of Beijing in 1215 marked the loss of all the territory north of the Huang He (Yellow River) to the Mongols; during the following years the Jin empire was reduced to the role of a buffer state between the Mongols in the north and the Chinese Song empire in the south. Other campaigns were launched against central Asia.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fde12cfa-9546-4969-b0aa-b09854fc954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Based on the given context, answer the following question delimited by backticks: `Where did the mongols attack first?` context : {context}\".format(context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "57376e29-96a9-4585-8ec3-a318969bb90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given context, answer the following question delimited by backticks: `Where did the mongols attack first?` context : - Mongol empire, empire founded by Genghis Khan in 1206. Originating from the Mongol heartland in the Steppe of central Asia, by the late 13th century it spanned from the Pacific Ocean in the east to the Danube River and the shores of the Persian Gulf in the west. At its peak, it covered some 9 million square miles (23 million square km) of territory, making it the largest contiguous land empire in world history The year 1206, when Temüjin, son of Yesügei, was elected Genghis Khan of a federation of tribes on the banks of the Onon River, must be regarded as the beginning of the Mongol empire. This federation not only consisted of Mongols in the proper sense—that is, Mongol-speaking tribes—but also other Turkic tribes. Before 1206 Genghis Khan was but one of the tribal leaders fighting for supremacy in the steppe regions south and southeast of Lake Baikal; his victories over the Kereit and then the Naiman Turks, however, gave him undisputed authority over the whole of what is now Mongolia. A series of campaigns, some of them carried out simultaneously, followed. The first attack (1205–09) was directed against the Tangut kingdom of Hsi Hsia (Xi Xia), a northwestern border-state of China, and ended in a declaration of allegiance by the Xi Xia king. A subsequent campaign was aimed at north China, which at that time was ruled by the Tungusic Jin dynasty. The fall of Beijing in 1215 marked the loss of all the territory north of the Huang He (Yellow River) to the Mongols; during the following years the Jin empire was reduced to the role of a buffer state between the Mongols in the north and the Chinese Song empire in the south. Other campaigns were launched against central Asia.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ecefe-857f-4618-82ca-b9f3e0be1e55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
